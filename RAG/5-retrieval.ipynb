{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 155 0 (offset 0)\n",
      "Ignoring wrong pointing object 158 0 (offset 0)\n",
      "Ignoring wrong pointing object 160 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"files/apostila.pdf\",\n",
    "    \"files/LLM.pdf\",\n",
    "]\n",
    "\n",
    "pages = []\n",
    "\n",
    "## Cria uma lista com todos os documentos\n",
    "for path in paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    docs = loader.load()\n",
    "    pages.extend(docs)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"])\n",
    "\n",
    "docs = splitter.split_documents(pages)\n",
    "\n",
    "normalized_docs = []\n",
    "\n",
    "for doc in docs:\n",
    "    # Remove repeated dots, dashes and spaces\n",
    "    cleaned_text = doc.page_content\n",
    "    cleaned_text = \" \".join(cleaned_text.split())  # Remove extra whitespace\n",
    "    cleaned_text = cleaned_text.replace(\"....\", \"\")\n",
    "    cleaned_text = cleaned_text.replace(\"...\", \"\")\n",
    "    cleaned_text = cleaned_text.replace(\"..\", \"\")\n",
    "    cleaned_text = cleaned_text.replace(\"----\", \"-\")\n",
    "    cleaned_text = cleaned_text.replace(\"---\", \"-\")\n",
    "    cleaned_text = cleaned_text.replace(\"--\", \"-\")\n",
    "    cleaned_text = cleaned_text.replace(\"  \", \"\")\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    # Create new document with cleaned text\n",
    "    doc.page_content = cleaned_text\n",
    "    normalized_docs.append(doc)\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Sumário PREFÁCIO 1 1. INTRODUÇÃO 2 1.1 Característi cas da linguagem Python . 2' metadata={'source': 'files/LLM.pdf', 'page': 1, 'doc_id': 1}\n"
     ]
    }
   ],
   "source": [
    "for index, doc in enumerate(docs):\n",
    "    doc.metadata[\"source\"] = paths[index % len(paths)]\n",
    "    doc.metadata['doc_id'] = index\n",
    "\n",
    "print(docs[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "## Banco vetorial\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "dir = \"db/chroma_db_retrieval\"\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sematinc Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". Se você quiser se aprofundar um pouco mais e expandir seus conhecimentos e compreensão dos fundamentos dos LLMs, recomendamos conferir nosso curso sobre LLMs. Você aprenderá como desenvolver aplicativos prontos para produção com LLMs e se aprofundará na teoria por trás dos modelos de fundação\n",
      "{'doc_id': 141, 'page': 7, 'source': 'files/LLM.pdf'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      ". Se você quiser se aprofundar um pouco mais e expandir seus conhecimentos e compreensão dos fundamentos dos LLMs, recomendamos conferir nosso curso sobre LLMs. Você aprenderá como desenvolver aplicativos prontos para produção com LLMs e se aprofundará na teoria por trás dos modelos de fundação\n",
      "{'page': 7, 'source': 'files/LLM.pdf'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PARTE 1 Introdução Definição de LLM (tradução livre: grandes modelos de linguagem) LLMs são sistemas de IA desenvolvidos para processar e analisar enormes quantidades de dados de linguagem natural e, em seguida, usar essas informações para gerar respostas às solicitações dos usuários\n",
      "{'doc_id': 101, 'page': 1, 'source': 'files/LLM.pdf'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ask = \"O que é um LLM?\"\n",
    "\n",
    "docs = vector_store.similarity_search(ask, k=3)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Margina Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". Se você quiser se aprofundar um pouco mais e expandir seus conhecimentos e compreensão dos fundamentos dos LLMs, recomendamos conferir nosso curso sobre LLMs. Você aprenderá como desenvolver aplicativos prontos para produção com LLMs e se aprofundará na teoria por trás dos modelos de fundação\n",
      "{'doc_id': 141, 'page': 7, 'source': 'files/LLM.pdf'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PARTE 1 Introdução Definição de LLM (tradução livre: grandes modelos de linguagem) LLMs são sistemas de IA desenvolvidos para processar e analisar enormes quantidades de dados de linguagem natural e, em seguida, usar essas informações para gerar respostas às solicitações dos usuários\n",
      "{'doc_id': 101, 'page': 1, 'source': 'files/LLM.pdf'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      ". Conclusão e diretrizes gerais Em última análise, cada organização terá desafios únicos a superar, e não existe uma abordagem única para os LLMs. À medida que o mundo se torna mais orientado a dados, tudo, incluindo os LLMs, dependerá de uma base sólida de dados. Os LLMs são ferramentas incríveis, mas devem ser usados e implementados sobre essa base sólida de dados\n",
      "{'doc_id': 136, 'page': 6, 'source': 'files/apostila.pdf'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.max_marginal_relevance_search(ask, k=3, fetch_k=10)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". 2023 Os LLMs de código aberto começam a apresentar resultados cada vez mais impressionantes, com lançamentos como Dolly 2.0, LLaMA, Alpaca e Vicuna. O GPT-4 também é lançado, estabelecendo um novo referencial tanto em tamanho de parâmetros quanto em desempenho.\n",
      "{'doc_id': 109, 'page': 2, 'source': 'files/LLM.pdf'}\n",
      ". Comunidades como a Hugging Face reúnem centenas de milhares de modelos de contribuidores que podem ajudar a resolver muitos casos de uso específicos, como geração de texto, resumo e classificação. A comunidade de código aberto está rapidamente alcançando o desempenho dos modelos proprietários, mas ainda não conseguiu igualar o desempenho de algo como o GPT-4.\n",
      "{'doc_id': 131, 'page': 5, 'source': 'files/LLM.pdf'}\n",
      "E-BOOK Um guia compacto sobre Large Language Models (LLM)\n",
      "{'doc_id': 99, 'page': 0, 'source': 'files/LLM.pdf'}\n",
      ". 2012 Os avanços em arquiteturas de deep learning e conjuntos de dados maiores levaram ao desenvolvimento do GPT (Transformadores Pré-treinados Generativos). 2018 O Google apresentou o BERT (Bidirectional Encoder Representations from Transformers), que foi um grande salto na arquitetura e abriu caminho para futuros grandes modelos de linguagem\n",
      "{'doc_id': 107, 'page': 2, 'source': 'files/LLM.pdf'}\n",
      ". Embora este guia tenha como foco os modelos de linguagem, é fundamental compreender que eles representam apenas um elemento dentro do vasto espectro da IA generativa. Outras implementações notáveis de IA generativa incluem projetos como a geração de arte a partir de texto, áudio e vídeo, e certamente muitas outras novidades surgirão em breve.\n",
      "{'doc_id': 103, 'page': 1, 'source': 'files/LLM.pdf'}\n",
      "PARTE 1 Introdução Definição de LLM (tradução livre: grandes modelos de linguagem) LLMs são sistemas de IA desenvolvidos para processar e analisar enormes quantidades de dados de linguagem natural e, em seguida, usar essas informações para gerar respostas às solicitações dos usuários\n",
      "{'doc_id': 101, 'page': 1, 'source': 'files/LLM.pdf'}\n",
      ". Como você não está lidando com uma caixa preta de um serviço proprietário, existem técnicas que permitem pegar modelos de código aberto e treiná-los com seus dados específicos, melhorando significativamente o desempenho deles em seu domínio específico. Acreditamos que o futuro dos modelos de linguagem seguirá nessa direção, à medida que mais organizações desejem ter controle total e compreensão de seus LLMs\n",
      "{'doc_id': 135, 'page': 6, 'source': 'files/LLM.pdf'}\n",
      "PARTE 2 Compreendendo os grandes modelos de linguagem (LLMs) O que são modelos de linguagem e como eles funcionam? Os grandes modelos de linguagem são sistemas avançados de inteligência artificial que recebem entradas e geram respostas semelhantes às de seres humanos em forma de texto. Eles funcionam primeiro analisando enormes quantidades de dados e criando uma estrutura interna que modela os conjuntos de dados de linguagem natural nos quais foram treinados\n",
      "{'doc_id': 111, 'page': 3, 'source': 'files/LLM.pdf'}\n",
      ". Em seguida, continue com esses prompts e os LLMs podem gerar um primeiro rascunho para você desenvolver. Use-os para criar ideias e faça perguntas ao LLM para ajudar a se inspirar. Observação: a maioria dos LLMs não é treinada para ser uma máquina de fatos. Eles sabem como usar a linguagem, mas podem não saber quem ganhou o grande evento esportivo do ano passado. É sempre importante verificar os fatos e entender as respostas antes de usá-las como referência.\n",
      "{'doc_id': 123, 'page': 4, 'source': 'files/LLM.pdf'}\n",
      ". Se eles existem há tantos anos, por que só agora estão ganhando destaque? Alguns avanços recentes trouxeram grande destaque à IA generativa e aos grandes modelos de linguagem: AVANÇOS EM TÉCNICAS Nos últimos anos, houve avanços significativos nas técnicas usadas para treinar esses modelos, resultando em grandes melhorias de desempenho. Notavelmente, um dos maiores saltos de desempenho veio da integração do feedback humano diretamente no processo de treinamento\n",
      "{'doc_id': 113, 'page': 3, 'source': 'files/LLM.pdf'}\n"
     ]
    }
   ],
   "source": [
    "ask = \"O que a apostila de LLM fala sobre o OpenAI e sobre o ChatGPT?\"\n",
    "\n",
    "docs = vector_store.similarity_search(ask, k=10, filter={\"source\": \"files/LLM.pdf\"})\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Aided Retrieval = Melhora a busca dentro do RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tive que fazer \"manualmente pq o Chroma n tem suport para SelfQueryRetriever mostrado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"Nome da apostila de onde o texto foi extraido. Pode ser 'apostila.pdf' ou 'LLM.pdf'\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"A página da apostila de onde o texto foi extraido. Número inteiro\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Reformulada: \"Conteúdo sobre OpenAI e ChatGPT na apostila LLM\"\n",
      "\n",
      "Filtro: \n",
      "```json\n",
      "{\n",
      "  \"source\": \"LLM.pdf\"\n",
      "}\n",
      "```\n",
      "Query reformulada: \"Conteúdo sobre OpenAI e ChatGPT na apostila LLM\"\n",
      "Filtro sugerido: {'source': 'LLM.pdf'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 1. Instancia o LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# 2. Descrição dos metadados (AttributeInfo que você já tem)\n",
    "metadata_info = [\n",
    "    {\n",
    "        \"name\": \"source\",\n",
    "        \"description\": \"Nome da apostila de onde o texto foi extraído. Pode ser 'apostila.pdf' ou 'LLM.pdf'\",\n",
    "        \"type\": \"string\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"page\",\n",
    "        \"description\": \"A página da apostila de onde o texto foi extraído. Número inteiro.\",\n",
    "        \"type\": \"integer\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# 3. Gera descrição dos atributos\n",
    "attribute_descriptions = \"\\n\".join(\n",
    "    f\"- {attr['name']}: {attr['description']} (tipo: {attr['type']})\"\n",
    "    for attr in metadata_info\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Função para criar o prompt\n",
    "def create_prompt(user_query):\n",
    "    return f\"\"\"\n",
    "Você é um assistente que ajuda a melhorar consultas em uma base de dados vetorial.\n",
    "Aqui estão os metadados disponíveis:\n",
    "{attribute_descriptions}\n",
    "\n",
    "A consulta do usuário é:\n",
    "\\\"{user_query}\\\"\n",
    "\n",
    "Tarefa:\n",
    "1. Reescreva a consulta para melhorar a busca.\n",
    "2. Sugira um filtro baseado nos metadados disponíveis (em formato JSON).\n",
    "\n",
    "Responda no formato:\n",
    "Query Reformulada: <texto>\n",
    "Filtro: <JSON>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 5. Pergunta do usuário\n",
    "user_query = \"O que a apostila de LLM fala sobre o OpenAI e sobre o ChatGPT?\"\n",
    "\n",
    "# 6. Gera o prompt e faz o LLM gerar a reformulação\n",
    "prompt = create_prompt(user_query)\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# 7. Parseia a resposta\n",
    "print(response.content)\n",
    "\n",
    "reformulated_query = re.search(r\"Query Reformulada:\\s*(.*)\", response.content).group(1)\n",
    "\n",
    "# Novo regex para pegar o JSON dentro de blocos ```\n",
    "filter_match = re.search(r\"```json\\s*(\\{.*\\})\\s*```\", response.content, re.DOTALL)\n",
    "\n",
    "if filter_match:\n",
    "    filter_json = filter_match.group(1)\n",
    "    filter_dict = json.loads(filter_json)\n",
    "else:\n",
    "    print(\"Erro: Não foi possível extrair o filtro.\")\n",
    "    filter_dict = {}\n",
    "\n",
    "print(\"Query reformulada:\", reformulated_query)\n",
    "print(\"Filtro sugerido:\", filter_dict)\n",
    "\n",
    "# 8. Faz a busca no seu Chroma vector_store\n",
    "docs = vector_store.similarity_search(query=reformulated_query, k=5, filter=filter_dict)\n",
    "\n",
    "\n",
    "# 9. Exibe resultados\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
